# ğŸ¤– N8N Workflow cho CTU Auto Crawl

## ğŸ“‹ Setup N8N

### 1. CÃ i Ä‘áº·t N8N
```bash
npm install -g n8n
# hoáº·c
npx n8n
```

### 2. Cháº¡y N8N
```bash
n8n start
# Má»Ÿ: http://localhost:5678
```

## ğŸ”„ Workflow Design

### Node 1: Manual Trigger
- **Type**: Manual Trigger
- **Input**: 
  - `start_url`: URL báº¯t Ä‘áº§u
  - `max_depth`: Äá»™ sÃ¢u tá»‘i Ä‘a (default: 3)
  - `max_urls`: URLs tá»‘i Ä‘a má»—i level (default: 5)

### Node 2: Initialize
- **Type**: Code
- **Function**: Setup variables
```javascript
return [
  {
    json: {
      current_urls: [items[0].json.start_url],
      level: 1,
      max_depth: items[0].json.max_depth || 3,
      max_urls: items[0].json.max_urls || 5,
      all_qa_pairs: [],
      crawled_urls: []
    }
  }
];
```

### Node 3: Level Loop
- **Type**: Loop Over Items
- **Expression**: `{{$json.level <= $json.max_depth && $json.current_urls.length > 0}}`

### Node 4: URL Loop  
- **Type**: Loop Over Items
- **Items**: `{{$json.current_urls.slice(0, $json.max_urls)}}`

### Node 5: HTTP Crawl
- **Type**: HTTP Request
- **Method**: GET
- **URL**: `{{$json.url}}`
- **Headers**: 
  ```json
  {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
  }
  ```

### Node 6: Clean HTML
- **Type**: Code
- **Function**: Clean HTML content
```javascript
const html = items[0].binary.data.toString();

// Remove scripts and styles
let content = html.replace(/<script[^>]*>.*?<\/script>/gis, '');
content = content.replace(/<style[^>]*>.*?<\/style>/gis, '');

// Extract text
content = content.replace(/<[^>]+>/g, ' ');
content = content.replace(/\s+/g, ' ').trim();

// Limit length
content = content.substring(0, 8000);

return [
  {
    json: {
      url: items[0].json.url,
      content: content
    }
  }
];
```

### Node 7: OpenAI Extract
- **Type**: OpenAI
- **Operation**: Chat
- **Model**: gpt-4o-mini
- **Messages**:
```json
[
  {
    "role": "system",
    "content": "Tráº£ vá» JSON há»£p lá»‡ vá» tuyá»ƒn sinh CTU."
  },
  {
    "role": "user", 
    "content": "PhÃ¢n tÃ­ch ná»™i dung tuyá»ƒn sinh CTU:\n\n{{$json.content}}\n\nTráº£ vá» JSON:\n{\n  \"qa_pairs\": [\n    {\n      \"question\": \"CÃ¢u há»i tiáº¿ng Viá»‡t\",\n      \"answer\": \"Tráº£ lá»i chi tiáº¿t\",\n      \"category\": \"nganh_hoc\",\n      \"source\": \"{{$json.url}}\"\n    }\n  ],\n  \"urls\": [\"url1\", \"url2\"]\n}\n\nCHá»ˆ tráº£ vá» JSON."
  }
]
```

### Node 8: Process Results
- **Type**: Code
- **Function**: Process OpenAI response
```javascript
const response = JSON.parse(items[0].json.choices[0].message.content);
const qa_pairs = response.qa_pairs || [];
const extracted_urls = response.urls || [];

// Filter CTU URLs
const ctu_indicators = ['ctu.edu.vn', 'tuyensinh', 'nganh', 'hoc-phi'];
const valid_urls = extracted_urls.filter(url => 
  ctu_indicators.some(indicator => url.toLowerCase().includes(indicator))
);

return [
  {
    json: {
      qa_pairs: qa_pairs,
      next_urls: valid_urls,
      current_url: items[0].json.url
    }
  }
];
```

### Node 9: Save Level Data
- **Type**: Write Binary File
- **File Path**: `data/auto_crawl/n8n_level_{{$json.level}}.json`
- **Data**: 
```json
{
  "level": "{{$json.level}}",
  "timestamp": "{{$now}}",
  "qa_pairs": "{{$json.all_qa_pairs}}",
  "urls": "{{$json.next_urls}}"
}
```

### Node 10: Add to Dataset
- **Type**: Execute Command
- **Command**: `python`
- **Arguments**: `["scripts/add_new_data.py", "data/auto_crawl/n8n_level_{{$json.level}}.json"]`

### Node 11: Next Level
- **Type**: Code
- **Function**: Prepare next level
```javascript
return [
  {
    json: {
      current_urls: items[0].json.next_urls,
      level: items[0].json.level + 1,
      max_depth: items[0].json.max_depth,
      max_urls: items[0].json.max_urls,
      all_qa_pairs: [...items[0].json.all_qa_pairs, ...items[0].json.qa_pairs],
      crawled_urls: [...items[0].json.crawled_urls, items[0].json.current_url]
    }
  }
];
```

## ğŸ¯ Workflow Features

### âœ… **Tá»± Ä‘á»™ng hoÃ n toÃ n**
- Chá»‰ cáº§n nháº­p URL ban Ä‘áº§u
- Tá»± Ä‘á»™ng crawl Ä‘á»‡ quy
- Tá»± Ä‘á»™ng thÃªm vÃ o dataset

### âœ… **Error Handling**
- Retry khi HTTP request fail
- Skip URLs lá»—i
- Continue vá»›i URLs khÃ¡c

### âœ… **Monitoring**
- Real-time progress
- Log chi tiáº¿t
- Email notification khi done

### âœ… **Scheduling**
- Cháº¡y hÃ ng ngÃ y/tuáº§n
- Crawl URLs má»›i tá»± Ä‘á»™ng
- Update dataset liÃªn tá»¥c

## ğŸš€ **CÃ¡ch sá»­ dá»¥ng:**

1. **Import workflow** vÃ o N8N
2. **Set OpenAI API key** trong credentials
3. **Click "Execute Workflow"**
4. **Nháº­p URL** vÃ  parameters
5. **Ngá»“i uá»‘ng cÃ  phÃª** â˜• - N8N lÃ m háº¿t!

## ğŸ’¡ **Lá»£i Ã­ch:**

- ğŸ¯ **Zero coding** - Chá»‰ kÃ©o tháº£
- ğŸ”„ **Visual workflow** - Dá»… hiá»ƒu, dá»… sá»­a
- ğŸ“Š **Real-time monitoring** - Theo dÃµi live
- âš¡ **Auto retry** - KhÃ´ng lo lá»—i
- ğŸ“… **Scheduling** - Cháº¡y tá»± Ä‘á»™ng
- ğŸ”” **Notifications** - BÃ¡o khi xong

**ÄÆ¡n giáº£n hÆ¡n Python scripts ráº¥t nhiá»u!** ğŸ‰ 